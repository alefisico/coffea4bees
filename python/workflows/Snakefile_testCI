analysis_container = "/cvmfs/unpacked.cern.ch/gitlab-registry.cern.ch/cms-cmu/coffea4bees:latest"
combine_container = "/cvmfs/unpacked.cern.ch/gitlab-registry.cern.ch/cms-analysis/general/combine-container:CMSSW_11_3_4-combine_v9.1.0-harvester_v2.1.0"

output_dir = "CI_output"
outputs = []

output_code = [ 
  f"{output_dir}/analysis_helpers_job.log",
  f"{output_dir}/kappa_framework.log",
  f"{output_dir}/jet_clustering.log",
  f"{output_dir}/trig_emulator.log",
  f"{output_dir}/memory_test.log"
]
# outputs.extend(output_code)

output_skimmer = [
  f"{output_dir}/skimmer_basic_test_job.log",
  f"{output_dir}/skimmer_test_job/picoaod_datasets_GluGluToHHTo4B_cHHH0_UL18.yml",
  f"{output_dir}/skimmer_analysis_test_job/test_skimmer.coffea",
  f"{output_dir}/skimmer_analysis_cutflow_job/test_dump_skimmer_cutflow.yml"
]
outputs.extend(output_skimmer)

# outputs.append()

output_skimmer_boosted = [
  f"{output_dir}/skimmer_boosted_job.log",
]
# outputs.extend(output_skimmer_boosted)

output_synthetic_dataset_make = [
  f"{output_dir}/synthetic_dataset_make_dataset/picoaod_datasets_declustered_test_UL18.yml",
  f"{output_dir}/synthetic_dataset_analyze/test_synthetic_datasets.coffea",
  f"{output_dir}/synthetic_dataset_analyze_cutflow/test_dump_cutflow_synthetic_datasets.yml"
]

output_synthetic_dataset_make_Run3 = [
  f"{output_dir}/synthetic_dataset_make_dataset_Run3/picoaod_datasets_declustered_test_2023_BPix.yml",
  f"{output_dir}/synthetic_dataset_analyze_Run3/test_synthetic_datasets.coffea",
  f"{output_dir}/synthetic_dataset_analyze_cutflow_Run3/test_dump_cutflow_synthetic_datasets.yml"
]

# outputs.extend(output_synthetic_dataset_make_dataset)

output_synthetic_dataset_analyze = [
  f"{output_dir}/synthetic_dataset_cluster/test_synthetic_datasets.coffea",
  f"{output_dir}/synthetic_dataset_plot_job/jet-splitting-PDFs-test/clustering_pdfs_vs_pT_RunII.yml"
]

output_synthetic_dataset_analyze_Run3 = [
  f"{output_dir}/synthetic_dataset_cluster_Run3/test_synthetic_datasets.coffea",
]

# outputs.extend(output_synthetic_dataset_analyze)


output_weights_trigger = [
  f"{output_dir}/weights_trigger_friendtree_job/trigger_weights_friends.json",
  f"{output_dir}/weights_trigger_friendtree_job/GluGluToHHTo4B_cHHH1_UL18/trigWeight.chunk1.root",
  f"{output_dir}/weights_trigger_analysis_job/test_trigWeight.coffea",
  f"{output_dir}/weights_trigger_cutflow_job/test_dump_cutflow_trigWeight.yml"
]
# outputs.extend(output_weights_trigger)


output_analysis = [
  f"{output_dir}/analysis_test_job/test_databkgs.coffea",
  f"{output_dir}/analysis_signals_test_job/test_signal.coffea",
  f"{output_dir}/analysis_merge_test_job/test.coffea",
  f"{output_dir}/analysis_make_jcm_weights_job/testJCM_ROOT/jetCombinatoricModel_SB_.yml",
  f"{output_dir}/analysis_plot_job/RunII/passPreSel/fourTag/SR/SvB_MA_ps_zz.pdf",
  f"{output_dir}/analysis_iplot_job.log",
  f"{output_dir}/baseclass_test_job/test_dumpPlotCounts.yml",
  f"{output_dir}/analysis_cutflow_job/test_dump_cutflow.yml",
  f"{output_dir}/analysis_cutflow_dilepttbar_job/test_dump_cutflow.yml",
]
# outputs.extend(output_analysis)

output_classifier_friendtree = [
  f"{output_dir}/classifier_friendtree_job/classifier_friendtree.yml"
]
# outputs.extend(output_classifier_friendtree)

output_topreco_friendtree = [
  f"{output_dir}/topreco_friendtree_job/top_reconstruction_friendtree.json"
]
# outputs.extend(output_topreco_friendtree)

output_unsup = [
  f"{output_dir}/analysis_test_job_unsup/test_unsup.coffea",
  f"{output_dir}/analysis_plot_job_unsup/RunII/passPreSel/fourTag/SR/mix_v0/v4j_mass.pdf",
  f"{output_dir}/analysis_cutflow_job_unsup/test_dump_cutflow_unsup.yml"
]
# outputs.extend(output_unsup)

output_mixeddata = [
  f"{output_dir}/analysis_test_mixed_job/testMixedData.json",
  f"{output_dir}/analysis_test_mixed_job/testMixedData.coffea",
  f"{output_dir}/twoStageClosure_test_job/test_dump_twoStageClosureInputsCounts.yml",
  f"{output_dir}/analysis_mixed_cutflow_job/test_dump_MixedData.yml"
]
# outputs.extend(output_mixeddata)

output_systematics = [
  f"{output_dir}/analysis_systematics_test_job/test_systematics.coffea",
  f"{output_dir}/analysis_systematics_cutflow_job/test_dump_systematics_cutflow.yml"
]
# outputs.extend(output_systematics)

output_run3 = [
  f"{output_dir}/analysis_test_job_Run3/test.coffea",
  f"{output_dir}/analysis_cutflow_job_Run3/test_dump_cutflow.yml"
]
# outputs.extend(output_run3)

output_synthetic_run3 = [
  f"{output_dir}/synthetic_dataset_make_dataset_Run3/picoaod_datasets_declustered_test_2023_BPix.yml",
  f"{output_dir}/synthetic_dataset_analyze_Run3/test_synthetic_datasets.coffea",
  f"{output_dir}/synthetic_dataset_analyze_cutflow_Run3/test_dump_cutflow_synthetic_datasets.yml"
]
# outputs.extend(output_synthetic_run3)

output_SvB_friendtree = [
  f"{output_dir}/SvB_friendtree_job/make_friend_SvB.json",
  f"{output_dir}/SvB_friendtree_analysis_job/test_SvB_friend.coffea",
  f"{output_dir}/SvB_friendtree_cutflow_job/test_dump_cutflow_SvB_friend.yml"
]


rule all:
    input: outputs


###### THIS IS WHERE THE RULES START ######

rule analysis_helpers_job:
    container: analysis_container
    log: f"{output_dir}/analysis_helpers_job.log"
    shell: "source scripts/analysis-helpers-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule kappa_framework:
    container: analysis_container
    log: f"{output_dir}/kappa_framework.log"
    shell: "source scripts/baseclass-kappa-framework.sh {output_dir}/ 2>&1 | tee -a {log}"

rule jet_clustering:
    container: analysis_container
    log: f"{output_dir}/jet_clustering.log"
    shell: "source scripts/jet-clustering-tests.sh {output_dir}/ 2>&1 | tee -a {log}"

rule trig_emulator:
    container: analysis_container
    log: f"{output_dir}/trig_emulator.log"
    shell: "source scripts/trig-emulator-tests.sh {output_dir}/ 2>&1 | tee -a {log}"

rule memory_test:
    container: analysis_container
    log: f"{output_dir}/memory_test.log"
    shell: "source scripts/memory_test.sh {output_dir}/ 2>&1 | tee -a {log}"

rule skimmer_test_job:
    container: analysis_container
    log: f"{output_dir}/skimmer_test_job.log"
    output: f"{output_dir}/skimmer_test_job/picoaod_datasets_GluGluToHHTo4B_cHHH0_UL18.yml"
    shell: "source scripts/skimmer-test-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule skimmer_basic_test_job:
    container: analysis_container
    log: f"{output_dir}/skimmer_basic_test_job.log"
    shell: "source scripts/skimmer-basic-test-job.sh {output_dir}/ 2>&1 | tee -a {log}"  

rule skimmer_boosted_job:
    container: analysis_container
    log: f"{output_dir}/skimmer_boosted_job.log"
    shell: "source scripts/skimmer-boosted-job.sh {output_dir}/ 2>&1 | tee -a {log}"  

rule synthetic_dataset_make_dataset:
    container: analysis_container
    log: f"{output_dir}/synthetic_dataset_make_dataset.log"
    output: f"{output_dir}/synthetic_dataset_make_dataset/picoaod_datasets_declustered_test_UL18.yml",
    shell: "source scripts/synthetic-dataset-make-dataset.sh {output_dir}/ 2>&1 | tee -a {log}"

rule weights_trigger_friendtree_job:
    container: analysis_container
    log: f"{output_dir}/weights_trigger_friendtree_job.log"
    output: 
      f"{output_dir}/weights_trigger_friendtree_job/trigger_weights_friends.json",
      f"{output_dir}/weights_trigger_friendtree_job/GluGluToHHTo4B_cHHH1_UL18/trigWeight.chunk1.root"
    shell: "source scripts/weights-trigger-friendtree-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule classifier_friendtree_job:
    container: analysis_container
    log: f"{output_dir}/classifier_friendtree_job.log"
    output: f"{output_dir}/classifier_friendtree_job/classifier_friendtree.yml"
    shell: "source scripts/classifier-friendtree-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule topreco_friendtree_job:
    container: analysis_container
    log: f"{output_dir}/topreco_friendtree_job.log"
    output: f"{output_dir}/topreco_friendtree_job/top_reconstruction_friendtree.json"
    shell: "source scripts/topreco-friendtree-job.sh {output_dir}/ 2>&1 | tee -a {log}"


rule analysis_test_job:
    output: f"{output_dir}/analysis_test_job/test_databkgs.coffea" 
    log: f"{output_dir}/analysis_test_job.log"
    container: analysis_container
    shell: "source scripts/analysis-test-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule analysis_signals_test_job:
    output: f"{output_dir}/analysis_signals_test_job/test_signal.coffea" 
    log: f"{output_dir}/analysis_signals_test_job.log"
    container: analysis_container
    shell: "source scripts/analysis-signals-test-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule analysis_merge_test_job:
    input:
        f"{output_dir}/analysis_test_job/test_databkgs.coffea",
        f"{output_dir}/analysis_signals_test_job/test_signal.coffea"
    output: f"{output_dir}/analysis_merge_test_job/test.coffea" 
    log: f"{output_dir}/analysis_merge_test_job.log"
    container: analysis_container
    shell: "source scripts/analysis-merge-test-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule analysis_test_job_truthStudy:
    output: f"{output_dir}/analysis_test_job_truthStudy/test_truthStudy.coffea" 
    log: f"{output_dir}/analysis_test_job_truthStudy.log"
    container: analysis_container
    shell: "source scripts/analysis-test-job-truthStudy.sh {output_dir}/ 2>&1 | tee -a {log}"

rule synthetic_dataset_cluster:
    output: f"{output_dir}/synthetic_dataset_cluster/test_synthetic_datasets.coffea" 
    log: f"{output_dir}/synthetic_dataset_cluster.log"
    container: analysis_container
    shell: "source scripts/synthetic-dataset-cluster.sh {output_dir}/ 2>&1 | tee -a {log}"


rule analysis_test_job_unsup:
    output: f"{output_dir}/analysis_test_job_unsup/test_unsup.coffea" 
    log: f"{output_dir}/analysis_test_job_unsup.log"
    container: analysis_container
    shell: "source scripts/analysis-test-job-unsup.sh {output_dir}/ 2>&1 | tee -a {log}"

rule analysis_test_mixed_job:
    output: 
        f"{output_dir}/analysis_test_mixed_job/testMixedData.json",
        f"{output_dir}/analysis_test_mixed_job/testMixedData.coffea"
    log: f"{output_dir}/analysis_test_mixed_job.log"
    container: analysis_container
    shell: "source scripts/analysis-test-mixed-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule analysis_systematics_test_job:
    output: f"{output_dir}/analysis_systematics_test_job/test_systematics.coffea" 
    log: f"{output_dir}/analysis_systematics_test_job.log"
    container: analysis_container
    shell: "source scripts/analysis-systematics-test-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule skimmer_analysis_test_job:
    input: f"{output_dir}/skimmer_test_job/picoaod_datasets_GluGluToHHTo4B_cHHH0_UL18.yml"
    output: f"{output_dir}/skimmer_analysis_test_job/test_skimmer.coffea"
    log: f"{output_dir}/skimmer_analysis_test_job.log"
    container: analysis_container
    shell: "source scripts/skimmer-analysis-test-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule synthetic_dataset_analyze:
    input: f"{output_dir}/synthetic_dataset_make_dataset/picoaod_datasets_declustered_test_UL18.yml"
    output: f"{output_dir}/synthetic_dataset_analyze/test_synthetic_datasets.coffea" 
    log: f"{output_dir}/synthetic_dataset_analyze.log"
    container: analysis_container
    shell: "source scripts/synthetic-dataset-analyze.sh {output_dir}/ 2>&1 | tee -a {log}"

rule synthetic_dataset_analyze_Run3:
    input: f"{output_dir}/synthetic_dataset_make_dataset_Run3/picoaod_datasets_declustered_test_2023_BPix.yml"
    output: f"{output_dir}/synthetic_dataset_analyze_Run3/test_synthetic_datasets.coffea" 
    log: f"{output_dir}/synthetic_dataset_analyze_Run3.log"
    container: analysis_container
    shell: "source scripts/synthetic-dataset-analyze-Run3.sh {output_dir}/ 2>&1 | tee -a {log}"


rule weights_trigger_analysis_job:
    input: f"{output_dir}/weights_trigger_friendtree_job/trigger_weights_friends.json"
    output: f"{output_dir}/weights_trigger_analysis_job/test_trigWeight.coffea"
    log: f"{output_dir}/weights_trigger_analysis_job.log"
    container: analysis_container
    shell: "source scripts/weights-trigger-analysis-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule analysis_make_jcm_weights_job:
    input: f"{output_dir}/analysis_merge_test_job/test.coffea"
    output: f"{output_dir}/analysis_make_jcm_weights_job/testJCM_ROOT/jetCombinatoricModel_SB_.yml"
    log: f"{output_dir}/analysis_make_jcm_weights_job.log"
    container: analysis_container
    shell: "source scripts/analysis-make-jcm-weights-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule twoStageClosure_test_job:
    input: f"{output_dir}/analysis_test_mixed_job/testMixedData.json"
    output: f"{output_dir}/twoStageClosure_test_job/test_dump_twoStageClosureInputsCounts.yml"
    log: f"{output_dir}/twoStageClosure_test_job.log"
    shell:
      """
      export APPTAINER_CACHEDIR="/tmp/$(whoami)/apptainer_cache"
      export APPTAINER_TMPDIR="/tmp/.apptainer/"

      APPTAINER_SHELL=$(which bash) apptainer exec -B .:/home/cmsusr/coffea4bees \
      --pwd /home/cmsusr/coffea4bees/  \
      {combine_container} \
      /bin/bash -c "export LANG=C && export LC_ALL=C && \
       source /cvmfs/cms.cern.ch/cmsset_default.sh && \
       cd /home/cmsusr/CMSSW_11_3_4/ && \
       cmsenv && \
       cd - && \
       source scripts/analysis-runTwoStageClosure-ROOT.sh {output_dir}/ 2>&1 | tee -a {log}"
      """

rule analysis_plot_job:
    input: f"{output_dir}/analysis_merge_test_job/test.coffea"
    output: f"{output_dir}/analysis_plot_job/RunII/passPreSel/fourTag/SR/SvB_MA_ps_zz.pdf"
    log: f"{output_dir}/analysis_plot_job.log"
    container: analysis_container
    shell: "source scripts/analysis-plot-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule analysis_plot_job_unsup:
    input: f"{output_dir}/analysis_test_job_unsup/test_unsup.coffea"
    output: f"{output_dir}/analysis_plot_job_unsup/RunII/passPreSel/fourTag/SR/mix_v0/v4j_mass.pdf"
    log: f"{output_dir}/analysis_plot_job_unsup.log"
    container: analysis_container
    shell: "source scripts/analysis-plot-job-unsup.sh {output_dir}/ 2>&1 | tee -a {log}"

rule analysis_iplot_job:
    input: f"{output_dir}/analysis_merge_test_job/test.coffea"
    log: f"{output_dir}/analysis_iplot_job.log"
    container: analysis_container
    shell: "source scripts/analysis-iplot-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule baseclass_test_job:
    input: f"{output_dir}/analysis_merge_test_job/test.coffea"
    output: f"{output_dir}/baseclass_test_job/test_dumpPlotCounts.yml"
    log: f"{output_dir}/baseclass_test_job.log"
    container: analysis_container
    shell: "source scripts/baseclass-test-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule synthetic_dataset_plot_job:
    input: f"{output_dir}/synthetic_dataset_cluster/test_synthetic_datasets.coffea"
    output: f"{output_dir}/synthetic_dataset_plot_job/jet-splitting-PDFs-test/clustering_pdfs_vs_pT_RunII.yml"
    log: f"{output_dir}/synthetic_dataset_plot_job.log"
    container: analysis_container
    shell: "source scripts/synthetic-dataset-plot-job.sh {output_dir}/ 2>&1 | tee -a {log}"


rule analysis_cutflow_job:    
    input: f"{output_dir}/analysis_merge_test_job/test.coffea"
    output: f"{output_dir}/analysis_cutflow_job/test_dump_cutflow.yml"
    log: f"{output_dir}/analysis_cutflow_job.log"
    container: analysis_container
    shell: "source scripts/analysis-cutflow-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule analysis_cutflow_dilepttbar_job:    
    input: f"{output_dir}/analysis_test_job/test_databkgs.coffea"
    output: f"{output_dir}/analysis_cutflow_dilepttbar_job/test_dump_cutflow.yml"
    log: f"{output_dir}/analysis_cutflow_dilepttbar_job.log"
    container: analysis_container
    shell: "source scripts/analysis-cutflow-dilepttbar-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule analysis_mixed_cutflow_job:    
    input: f"{output_dir}/analysis_test_mixed_job/testMixedData.coffea"
    output: f"{output_dir}/analysis_mixed_cutflow_job/test_dump_MixedData.yml"
    log: f"{output_dir}/analysis_mixed_cutflow_job.log"
    container: analysis_container
    shell: "source scripts/analysis-mixed-cutflow-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule skimmer_analysis_cutflow_job:    
    input: f"{output_dir}/skimmer_analysis_test_job/test_skimmer.coffea"
    output: f"{output_dir}/skimmer_analysis_cutflow_job/test_dump_skimmer_cutflow.yml"
    log: f"{output_dir}/skimmer_analysis_cutflow_job.log"
    container: analysis_container
    shell: "source scripts/skimmer-analysis-cutflow-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule analysis_systematics_cutflow_job:    
    input: f"{output_dir}/analysis_systematics_test_job/test_systematics.coffea"
    output: f"{output_dir}/analysis_systematics_cutflow_job/test_dump_systematics_cutflow.yml"
    log: f"{output_dir}/analysis_systematics_cutflow_job.log"
    container: analysis_container
    shell: "source scripts/analysis-systematics-cutflow-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule analysis_cutflow_job_unsup:    
    input: f"{output_dir}/analysis_test_job_unsup/test_unsup.coffea"
    output: f"{output_dir}/analysis_cutflow_job_unsup/test_dump_cutflow_unsup.yml"
    log: f"{output_dir}/analysis_cutflow_job_unsup.log"
    container: analysis_container
    shell: "source scripts/analysis-cutflow-job-unsup.sh {output_dir}/ 2>&1 | tee -a {log}"

rule synthetic_dataset_analyze_cutflow:
    input: f"{output_dir}/synthetic_dataset_analyze/test_synthetic_datasets.coffea"
    output: f"{output_dir}/synthetic_dataset_analyze_cutflow/test_dump_cutflow_synthetic_datasets.yml"
    log: f"{output_dir}/synthetic_dataset_analyze_cutflow.log"
    container: analysis_container
    shell: "source scripts/synthetic-dataset-analyze-cutflow.sh {output_dir}/ 2>&1 | tee -a {log}"

rule synthetic_dataset_analyze_cutflow_Run3:
    input: f"{output_dir}/synthetic_dataset_analyze_Run3/test_synthetic_datasets.coffea"
    output: f"{output_dir}/synthetic_dataset_analyze_cutflow_Run3/test_dump_cutflow_synthetic_datasets.yml"
    log: f"{output_dir}/synthetic_dataset_analyze_cutflow_Run3.log"
    container: analysis_container
    shell: "source scripts/synthetic-dataset-analyze-cutflow-Run3.sh {output_dir}/ 2>&1 | tee -a {log}"


rule weights_trigger_analysis_cutflow_job:
    input: f"{output_dir}/weights_trigger_analysis_job/test_trigWeight.coffea"
    output: f"{output_dir}/weights_trigger_cutflow_job/test_dump_cutflow_trigWeight.yml"
    log: f"{output_dir}/weights_trigger_cutflow_job.log"
    container: analysis_container
    shell: "source scripts/weights-trigger-cutflow-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule analysis_test_job_Run3:
    output: f"{output_dir}/analysis_test_job_Run3/test.coffea"
    log: f"{output_dir}/analysis_test_job_Run3.log"
    container: analysis_container
    shell: "source scripts/analysis-test-job-Run3.sh {output_dir}/ 2>&1 | tee -a {log}"

rule analysis_cutflow_job_Run3:
    input: f"{output_dir}/analysis_test_job_Run3/test.coffea"
    output: f"{output_dir}/analysis_cutflow_job_Run3/test_dump_cutflow.yml"
    log: f"{output_dir}/analysis_cutflow_job_Run3.log"
    container: analysis_container
    shell: "source scripts/analysis-cutflow-job-Run3.sh {output_dir}/ 2>&1 | tee -a {log}"

rule synthetic_dataset_make_dataset_Run3:
    output: f"{output_dir}/synthetic_dataset_make_dataset_Run3/picoaod_datasets_declustered_test_2023_BPix.yml"
    log: f"{output_dir}/synthetic_dataset_make_dataset_Run3.log"
    container: analysis_container
    shell: "source scripts/synthetic-dataset-make-dataset-Run3.sh {output_dir}/ 2>&1 | tee -a {log}"


rule SvB_friendtree_job:
    container: analysis_container
    log: f"{output_dir}/SvB_friendtree_job.log"
    output: f"{output_dir}/SvB_friendtree_job/make_friend_SvB.json"
    shell: "source scripts/SvB-friendtree-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule SvB_friendtree_analysis_job:
    input: f"{output_dir}/SvB_friendtree_job/make_friend_SvB.json"
    output: f"{output_dir}/SvB_friendtree_analysis_job/test_SvB_friend.coffea"
    log: f"{output_dir}/SvB_friendtree_analysis_job.log"
    container: analysis_container
    shell: "source scripts/SvB-friendtree-analysis-job.sh {output_dir}/ 2>&1 | tee -a {log}"

rule SvB_friendtree_cutflow_job:
    input: f"{output_dir}/SvB_friendtree_analysis_job/test_SvB_friend.coffea"
    output: f"{output_dir}/SvB_friendtree_cutflow_job/test_dump_cutflow_SvB_friend.yml"
    log: f"{output_dir}/SvB_friendtree_cutflow_job.log"
    container: analysis_container
    shell: "source scripts/SvB-friendtree-cutflow-job.sh {output_dir}/ 2>&1 | tee -a {log}"